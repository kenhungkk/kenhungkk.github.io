{
  "hash": "2e2ae0cad7a59cb49adc772d20020dae",
  "result": {
    "markdown": "---\ntitle: Normal distribution in Python\ndescription: Getting the hang of statistical computing in Python\nauthor: Kenneth Hung\ndate: 2020-08-04\ncategories:\n  - statistical computing\nexecute: \n  freeze: true\n---\n\n\nWorking on theoretical statistics, all of my work in my PhD was done in R. But for production code in industry, for the sake of speed and easier maintenance, I have taken up to implement some of my ideas in Python even when the prototyping is done in R. I did not expect to be learning this much by just looking at a normal distribution.\n\n## scipy.stats vs math\n\nSuppose we want to compute the CDF of a standard normal. An R user like me who is used to `pnorm(z)` would probably write this\n\n```python\nfrom scipy.stats import norm\n\nnorm.cdf(z)\n```\n\nBut another way is to use the `erf` function, given by\n\n\n$$\n\\text{erf}(z) = \\frac{2}{\\sqrt{\\pi}} \\int_0^z e^{-t^2} \\,dt.\n$$\n\n\nWe can then write\n\n\n::: {.cell}\n\n```{.python .cell-code}\nfrom math import erf\n\ndef phi(z):\n  return (1.0 + erf(z / sqrt(2.0))) / 2.0\n```\n:::\n\n\nIn fact this is [the given example](https://docs.python.org/3/library/math.html#math.erf) in the Python documentations for the `math` library.\n\nFor my purpose, this function needs to be run many times, so speed is definitely important here. We run it for 10000 times:\n\n\n::: {.cell}\n\n```{.python .cell-code}\nfrom timeit import default_timer\nfrom scipy.stats import norm\nfrom math import erf\n\ndef phi(z):\n  return (1.0 + erf(z / 1.4142135623730951)) / 2.0\n\nstart = default_timer()\nscipy_output = [norm.cdf(1) for i in range(10000)]\nend = default_timer()\nprint(\"scipy took:\", str(end - start))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nscipy took: 0.9739241569999999\n```\n:::\n\n```{.python .cell-code}\nstart = default_timer()\nmath_output = [phi(1) for i in range(10000)]\nend = default_timer()\nprint(\"math took:\", str(end - start))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nmath took: 0.011614696000000091\n```\n:::\n:::\n\n\nComputing using `erf` was a lot faster than using `scipy`, but that should not come as a surprise. Even in R, a loop without any vectorization is bound to be slow. After all, the strength of `scipy` is that it works well with `numpy` arrays. So let's vectorize it:\n\n\n::: {.cell}\n\n```{.python .cell-code}\nimport numpy\n\nstart = default_timer()\nnorm.cdf(numpy.repeat(1, 10000))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\narray([0.84134475, 0.84134475, 0.84134475, ..., 0.84134475, 0.84134475,\n       0.84134475])\n```\n:::\n\n```{.python .cell-code}\nend = default_timer()\nprint(\"scipy took:\", str(end - start))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nscipy took: 0.013408950000000086\n```\n:::\n:::\n\n\nToo bad that in my use case, the CDF of the normal distribution has to be computed in a loop, so I will go with the `erf` route...\n\n## erf vs erfc\n\n...which brings us to another question. How accurate is computing the CDF based on erf? The part where we add `erf` to `1.0` means that anything that is close to or smaller than the machine epsilon will get erased. What if we do care about the magnitude of the CDF far in the tail of the normal? With the time constraint, we cannot really call `norm.logcdf` here.\n\n\n::: {.cell}\n\n```{.python .cell-code}\n[phi(-z) for z in range(5, 15)]\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[2.8665157186802404e-07, 9.865876449133282e-10, 1.2798095916366492e-12, 6.106226635438361e-16, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n```\n:::\n:::\n\n\nWe can instead use `erfc`, defined as\n\n\n$$\n\\text{erfc}(z) = 1 - \\text{erf}(z).\n$$\n\n\nNow we have\n\n\n::: {.cell}\n\n```{.python .cell-code}\nfrom math import erfc\n\ndef phi(z):\n  return erfc(-z / 1.4142135623730951) / 2.0\n\n[phi(-z) for z in range(5, 15)]\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[2.866515718791945e-07, 9.865876450377014e-10, 1.2798125438858348e-12, 6.22096057427182e-16, 1.1285884059538425e-19, 7.619853024160593e-24, 1.9106595744986828e-28, 1.7764821120777016e-33, 6.117164399549921e-39, 7.793536819192798e-45]\n```\n:::\n:::\n\n\nIt preserved many more digits. It is curious how the Python documentations chose to use this example for `erf` instead of `erfc`. To check if this is correct, I run in R:\n\n\n::: {.cell}\n\n```{.r .cell-code}\npnorm(-(5:14))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n [1] 2.866516e-07 9.865876e-10 1.279813e-12 6.220961e-16 1.128588e-19\n [6] 7.619853e-24 1.910660e-28 1.776482e-33 6.117164e-39 7.793537e-45\n```\n:::\n:::\n\n\nwhich gave the exactly same numbers. Did R perhaps implement `pnorm` using `erfc` as well?",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}