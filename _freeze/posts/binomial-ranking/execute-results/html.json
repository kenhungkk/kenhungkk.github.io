{
  "hash": "96fc0adf71ac3c1fe7c9aac86b86d29a",
  "result": {
    "markdown": "---\ntitle: Binomial ranking with SARS data\ndescription: If deaths in each country follows a binomial distribution, how do we rank them by the probability parameter?\nauthor: Kenneth Hung\ndate: 2020-02-15\ncategories:\n  - multiple testing\n---\n\n\n## Introduction\n\nWith the coronavirus spreading to many countries, Rebecca asked me a curious question: how does the US perform during SARS compared to other regions in terms of survival rate? While we can compute the survival rate of all infected regions and rank them accordingly, we are ignoring the sampling variability. For example, South Africa that has one case but also one death, does not necessarily perform worse than Indonesia where there were two cases but both patients survived.\n\n## Setup\n\nOf course there are many other factors, but we can consider an idealized model where the number of patients, $n_i$ in each country is predetermined, but the number of deaths, $X_i$ is random and comes from a binomial draw:\n$$X_i \\sim \\text{Binomial}(n_i, p_i),$$\nwhere $p_i$ represent the chance of a patient dying in region $i$. We would then want to provide simultaneous confidence intervals for the rank of region $i$, $r_i$, as defined in @almohamad2022simultaneous:\n$$r_i = 1 + \\#\\{j \\ne i: p_j < p_i\\}$$\nThere is an obvious Bayesian way to achieve this. By setting up a reasonable prior, we can perform posterior draws of $p_i$ and search for confidence intervals of ranks that covers $(1 - \\alpha)$ of the posterior draws. Naturally this can be extended to an empirical Bayes way as well, as suggested in one of the comments in [this Cross Validated thread](https://stats.stackexchange.com/questions/157437/ranking-based-on-binomial-data-example-website-conversions). We want to focus on strict frequentist methods here.\n\n## Data\n\nI have never done data scraping, so I am glad that this led me to learn `rvest`. We read in the table from the [SARS page](https://en.wikipedia.org/wiki/Severe_acute_respiratory_syndrome#Epidemiology) on Wikipedia. It looks like this:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsuppressPackageStartupMessages({\n  library(dplyr)\n  library(ggplot2)\n  library(kableExtra)\n  library(rvest)\n  library(tidyr)\n})\n\ndata <- \"https://en.wikipedia.org/wiki/Severe_acute_respiratory_syndrome\" %>%\n  read_html %>%\n  html_nodes(xpath = '//*[@id=\"mw-content-text\"]/div/table[2]') %>%\n  html_table(fill = TRUE)\ndata <- data[[1]] %>%\n  setNames(c('region', 'cases', 'deaths', 'fatality', 'X1')) %>%\n  select(region, cases, deaths) %>%\n  filter(!grepl('total', tolower(region)), !grepl('\\\\^', region)) %>%\n  mutate(\n    region = trimws(gsub('\\\\[[[:print:]]\\\\]', '', region)),\n    cases = as.numeric(gsub(',', '', cases)),\n    deaths = as.numeric(gsub(',', '', deaths)),\n    fatality = deaths / cases\n  )\ndata %>% head() %>% kbl(format = \"markdown\")\n```\n\n::: {.cell-output-display}\n|region    | cases| deaths|  fatality|\n|:---------|-----:|------:|---------:|\n|China     |  5327|    349| 0.0655153|\n|Hong Kong |  1755|    299| 0.1703704|\n|Taiwan    |   346|     81| 0.2341040|\n|Canada    |   251|     43| 0.1713147|\n|Singapore |   238|     33| 0.1386555|\n|Vietnam   |    63|      5| 0.0793651|\n:::\n:::\n\n\n## Method 1: Simultaneous confidence intervals\n\nOne way is to construct simultaneous confidence intervals for each of the region, and \"project\" to figure out the ranks. We implement those here:\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\" code-summary=\"Show the code\"}\numpu.expfam.test <- function(x, prob, u = runif(1)) {\n  x <- x - min(which(prob != 0)) + 1\n  prob <- prob[min(which(prob != 0)):max(which(prob != 0))]\n  n <- length(prob)\n  if (x > n | x <= 0) {\n    return(0)\n  }\n  \n  mean.x <- sum(prob * 1:n)\n  # observation is mean\n  if (abs(x - mean.x) < .Machine$double.eps^0.5) {\n    return(1 - u * prob[x])\n  }\n  # observation is on lower tail\n  if (x < mean.x) {\n    x <- n + 1 - x\n    mean.x <- n + 1 - mean.x\n    prob <- rev(prob)\n  }\n  \n  # dot product with this vector gives the covariance with x\n  cov.vec <- prob * (1:n - mean.x)\n  \n  prob.hi <- sum(prob[-(1:x)]) + prob[x] * u\n  cov.tail <- sum(cov.vec[-(1:x)]) + cov.vec[x] * u\n  cov.cumsum <- cumsum(cov.vec) + cov.tail\n  lo <- min(which(cov.cumsum < 0))\n  prob.lo <- sum(prob[1:lo]) - cov.cumsum[lo] / cov.vec[lo] * prob[lo]\n  \n  prob.lo + prob.hi\n}\n\numpu.binom.test <- function(x, n, p, u = runif(1)) {\n  umpu.expfam.test(x + 1, dbinom(0:n, n, p), u)\n}\n\numau.binom.ci <- function(x, n, alpha, u = runif(1)) {\n  f <- function(p) {\n    umpu.binom.test(x, n, p, u) - alpha\n  }\n  tol <- .Machine$double.eps^0.5\n  if (x == 0) {\n    ci.lo <- 0\n  } else {\n    ci.lo <- uniroot(f, c(0, x / n), tol = tol)$root\n  }\n  if (x == n) {\n    ci.hi <- 1\n  } else {\n    ci.hi <- uniroot(f, c(x / n, 1), tol = tol)$root\n  }\n  c(ci.lo, ci.hi)\n}\n\n# delta is the difference in log-odds\numpu.binom.contrast.test <- function(x1, n1, x2, n2, delta = 0, u = runif(1)) {\n  log.prob <- dbinom(0:(x1 + x2), n1, 0.5, log = TRUE) +\n    dbinom((x1 + x2):0, n2, 0.5, log = TRUE) +\n    0:(x1 + x2) * delta\n  log.prob <- log.prob - max(log.prob)\n  prob <- exp(log.prob)\n  prob <- prob / sum(prob)\n  umpu.expfam.test(x1 + 1, prob, u)\n}\n```\n:::\n\n\nWe construct UMAU simultaneous confidence intervals:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nset.seed(20200215)\n\ndata.ci <- mapply(\n  umau.binom.ci,\n  data$deaths,\n  data$cases,\n  MoreArgs = list(alpha = 0.05 / nrow(data))\n) %>%\n  t %>%\n  data.frame %>%\n  setNames(c('ci.lo', 'ci.hi'))\ndata <- data %>% cbind(data.ci)\n\nggplot(\n  data,\n  aes(x = factor(region, region), y = fatality, ymin = ci.lo, ymax = ci.hi)\n) +\n  geom_point() +\n  geom_errorbar() +\n  theme_minimal() +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +\n  labs(x = \"Region\", y = \"Fatality\")\n```\n\n::: {.cell-output-display}\n![](binomial-ranking_files/figure-html/unnamed-chunk-3-1.png){fig-align='center' width=672}\n:::\n:::\n\nThese UMAU intervals are random by nature. Furthermore, the simultaneous coverage is achieved by Bonferroni correction here. A more fine-tuned analysis can be obtain by strategically distribute the type I error over the 29 regions, especially when some of these intervals are likely uninformative.\n\nWe can now compute the ranks for all parameters falling into the simultaneous confidence region\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndata %>%\n  mutate(\n    rank.lo = 1 + rowSums(outer(ci.lo, ci.hi, FUN = '-') >= 0),\n    rank.hi = rowSums(outer(ci.hi, ci.lo, FUN = '-') >= 0)\n  ) %>%\n  kbl(format = \"markdown\")\n```\n\n::: {.cell-output-display}\n|region         | cases| deaths|  fatality|     ci.lo|     ci.hi| rank.lo| rank.hi|\n|:--------------|-----:|------:|---------:|---------:|---------:|-------:|-------:|\n|China          |  5327|    349| 0.0655153| 0.0553309| 0.0767850|       1|      27|\n|Hong Kong      |  1755|    299| 0.1703704| 0.1431314| 0.2001229|       2|      31|\n|Taiwan         |   346|     81| 0.2341040| 0.1675014| 0.3108369|       2|      31|\n|Canada         |   251|     43| 0.1713147| 0.1038446| 0.2564828|       2|      31|\n|Singapore      |   238|     33| 0.1386555| 0.0791824| 0.2173352|       2|      31|\n|Vietnam        |    63|      5| 0.0793651| 0.0097358| 0.2311465|       1|      31|\n|United States  |    27|      0| 0.0000000| 0.0000000| 0.1884739|       1|      31|\n|Philippines    |    14|      2| 0.1428571| 0.0001477| 0.5865567|       1|      31|\n|Thailand       |     9|      2| 0.2222222| 0.0012364| 0.7285998|       1|      31|\n|Germany        |     9|      0| 0.0000000| 0.0000000| 0.5160983|       1|      31|\n|Mongolia       |     9|      0| 0.0000000| 0.0000000| 0.4660410|       1|      31|\n|France         |     7|      1| 0.1428571| 0.0000000| 0.7410531|       1|      31|\n|Australia      |     6|      0| 0.0000000| 0.0000000| 0.5821487|       1|      31|\n|Malaysia       |     5|      2| 0.4000000| 0.0022369| 0.9623212|       1|      31|\n|Sweden         |     5|      0| 0.0000000| 0.0000000| 0.7923318|       1|      31|\n|United Kingdom |     4|      0| 0.0000000| 0.0000000| 0.7418809|       1|      31|\n|Italy          |     4|      0| 0.0000000| 0.0000000| 0.8810932|       1|      31|\n|Brazil         |     3|      0| 0.0000000| 0.0000000| 0.8873430|       1|      31|\n|India          |     3|      0| 0.0000000| 0.0000000| 0.9577680|       1|      31|\n|South Korea    |     3|      0| 0.0000000| 0.0000000| 0.9277255|       1|      31|\n|Indonesia      |     2|      0| 0.0000000| 0.0000000| 0.9982266|       1|      31|\n|South Africa   |     1|      1| 1.0000000| 0.0000000| 1.0000000|       1|      31|\n|Colombia       |     1|      0| 0.0000000| 0.0000000| 1.0000000|       1|      31|\n|Kuwait         |     1|      0| 0.0000000| 0.0000000| 1.0000000|       1|      31|\n|Ireland        |     1|      0| 0.0000000| 0.0000000| 1.0000000|       1|      31|\n|Macao          |     1|      0| 0.0000000| 0.0000000| 1.0000000|       1|      31|\n|New Zealand    |     1|      0| 0.0000000| 0.0000000| 1.0000000|       1|      31|\n|Romania        |     1|      0| 0.0000000| 0.0000000| 1.0000000|       1|      31|\n|Russia         |     1|      0| 0.0000000| 0.0000000| 1.0000000|       1|      31|\n|Spain          |     1|      0| 0.0000000| 0.0000000| 1.0000000|       1|      31|\n|Switzerland    |     1|      0| 0.0000000| 0.0000000| 1.0000000|       1|      31|\n:::\n:::\n\n\n## Method 2: Simultaneous pairwise tests\n\nBinomial distributions is an exponential family, so contrasts like $p_i - p_j$ are amenable to UMPU tests. We can perform $\\binom{29}{2}$ pairwise tests, with Bonferroni correction, and draw conclusions about the ranks.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(113013)\n\npairwise.test <- by(\n  expand.grid(region1 = 1:nrow(data), region2 = 1:nrow(data)),\n  1:(nrow(data)^2),\n  function(pair) {\n    if (pair$region1 == pair$region2) {\n      return(1)\n    }\n    umpu.binom.contrast.test(\n      data$deaths[pair$region1],\n      data$cases[pair$region1],\n      data$deaths[pair$region2],\n      data$cases[pair$region2],\n      delta = 0\n    )\n  }\n) %>%\n  matrix(nrow(data), nrow(data))\npairwise.test[upper.tri(pairwise.test)] <- t(\n  pairwise.test\n)[upper.tri(pairwise.test)]\n\ndata %>%\n  select(-ci.lo, -ci.hi) %>%\n  mutate(\n    rank.lo = 1 +\n      rowSums(\n        (pairwise.test * choose(nrow(data), 2) < 0.05) &\n          (outer(data$fatality, data$fatality, FUN = \"-\") > 0)\n      ),\n    rank.hi = nrow(data) -\n      rowSums(\n        (pairwise.test * choose(nrow(data), 2) < 0.05) &\n          (outer(fatality, fatality, FUN = \"-\") < 0)\n      )\n  ) %>%\n  kbl(format = \"markdown\")\n```\n\n::: {.cell-output-display}\n|region         | cases| deaths|  fatality| rank.lo| rank.hi|\n|:--------------|-----:|------:|---------:|-------:|-------:|\n|China          |  5327|    349| 0.0655153|       1|      28|\n|Hong Kong      |  1755|    299| 0.1703704|       2|      31|\n|Taiwan         |   346|     81| 0.2341040|       2|      31|\n|Canada         |   251|     43| 0.1713147|       2|      31|\n|Singapore      |   238|     33| 0.1386555|       1|      31|\n|Vietnam        |    63|      5| 0.0793651|       1|      31|\n|United States  |    27|      0| 0.0000000|       1|      31|\n|Philippines    |    14|      2| 0.1428571|       1|      31|\n|Thailand       |     9|      2| 0.2222222|       1|      31|\n|Germany        |     9|      0| 0.0000000|       1|      31|\n|Mongolia       |     9|      0| 0.0000000|       1|      31|\n|France         |     7|      1| 0.1428571|       1|      31|\n|Australia      |     6|      0| 0.0000000|       1|      31|\n|Malaysia       |     5|      2| 0.4000000|       1|      31|\n|Sweden         |     5|      0| 0.0000000|       1|      31|\n|United Kingdom |     4|      0| 0.0000000|       1|      31|\n|Italy          |     4|      0| 0.0000000|       1|      31|\n|Brazil         |     3|      0| 0.0000000|       1|      31|\n|India          |     3|      0| 0.0000000|       1|      31|\n|South Korea    |     3|      0| 0.0000000|       1|      31|\n|Indonesia      |     2|      0| 0.0000000|       1|      31|\n|South Africa   |     1|      1| 1.0000000|       1|      31|\n|Colombia       |     1|      0| 0.0000000|       1|      31|\n|Kuwait         |     1|      0| 0.0000000|       1|      31|\n|Ireland        |     1|      0| 0.0000000|       1|      31|\n|Macao          |     1|      0| 0.0000000|       1|      31|\n|New Zealand    |     1|      0| 0.0000000|       1|      31|\n|Romania        |     1|      0| 0.0000000|       1|      31|\n|Russia         |     1|      0| 0.0000000|       1|      31|\n|Spain          |     1|      0| 0.0000000|       1|      31|\n|Switzerland    |     1|      0| 0.0000000|       1|      31|\n:::\n:::\n\n\nHere we are bounded to correct for all $\\binom{29}{2}$ tests, instead of taking advantage of Tukey's HSD, which incurs a much smaller penalty for multiple testing. Asymptotically we can always think of the likelihood as if it came from a Gaussian distribution and use Tukey's HSD, but we most definitely are not in any reasonable asymptotic regime here.\n\n## Thoughts\n\nAre there better, strictly frequentist methods for computing these rank confidence intervals? This alone seems hard, but there is a natural, even harder generalization of this problem: suppose we have a joint distribution of exponential families where the base measure does not need to be the same\n$$p_i(X_i; \\theta_i) = h(x_i) \\exp(\\theta_i x_i - A_i(\\theta_i)),$$\nis there a powerful method for ranking $\\theta_i$?",
    "supporting": [
      "binomial-ranking_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}